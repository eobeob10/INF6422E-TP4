{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "data1 = pd.read_csv('MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv')\n",
    "data2 = pd.read_csv('MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv')\n",
    "data3 = pd.read_csv('MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv')\n",
    "data4 = pd.read_csv('MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv')\n",
    "data5 = pd.read_csv('MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv')\n",
    "data6 = pd.read_csv('MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv')\n",
    "data7 = pd.read_csv('MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv')\n",
    "data8 = pd.read_csv('MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [data1,data2, data3,data4,data5, data6, data7, data8]\n",
    "\n",
    "print('Data dimensions: ')\n",
    "for i, data in enumerate(data_list, start = 1):\n",
    "  rows, cols = data.shape\n",
    "  print(f'Data{i} -> {rows} rows, {cols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(data_list)\n",
    "rows, cols = df.shape\n",
    "\n",
    "print('New dimension:')\n",
    "print(f'Number of rows: {rows}')\n",
    "print(f'Number of columns: {cols}')\n",
    "print(f'Total cells: {rows * cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting dataframes after concating to save memory\n",
    "for d in data_list: del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns by removing leading/trailing whitespace\n",
    "col_names = {col: col.strip() for col in df.columns}\n",
    "df.rename(columns = col_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from labels\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ±∞ with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Suppose the dataset has a 'Label' column\n",
    "df['Label'] = df['Label'].astype('category').cat.codes\n",
    "\n",
    "# Separate features & labels\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label'].values\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Unique labels in y:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "val_ratio = 0.15 / 0.85\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=val_ratio, \n",
    "    random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:  \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification for 70-15-15 split:\n",
    "\n",
    "70% Training: Enough data to learn robust patterns.\n",
    "\n",
    "15% Validation: A separate set for hyperparameter tuning (e.g., learning rate, noise multiplier for DP, etc.).\n",
    "\n",
    "15% Test: Kept strictly for final evaluation. This prevents overfitting to the validation set and provides an unbiased measure of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from opacus import PrivacyEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "val_dataset   = TensorDataset(X_val_t,   y_val_t)\n",
    "test_dataset  = TensorDataset(X_test_t,  y_test_t)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))  # If it's binary, likely 2\n",
    "model = SimpleMLP(input_dim, hidden_dim=64, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# DP hyperparameters\n",
    "noise_multiplier = 1.0\n",
    "max_grad_norm = 1.0\n",
    "epochs = 5\n",
    "delta = 1e-5\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    max_grad_norm=max_grad_norm,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # If multi-class, outputs have shape [batch_size, num_classes]\n",
    "            probs = torch.softmax(outputs, dim=1)[:,1]  # Probability of class=1\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_labels.append(target.cpu().numpy())\n",
    "            \n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "    acc = correct / total\n",
    "    return acc, np.concatenate(all_probs), np.concatenate(all_labels)\n",
    "\n",
    "test_acc, y_prob_test, y_test_true = evaluate(model, test_loader)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "y_pred_test = (y_prob_test >= 0.5).astype(int)\n",
    "\n",
    "prec = precision_score(y_test_true, y_pred_test,average='weighted')\n",
    "rec  = recall_score(y_test_true, y_pred_test,average='weighted')\n",
    "f1   = f1_score(y_test_true, y_pred_test,average='weighted')\n",
    "cm   = confusion_matrix(y_test_true, y_pred_test)\n",
    "\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = privacy_engine.get_epsilon(delta=delta)\n",
    "print(f\"ε = {epsilon:.2f} for δ = {delta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def remove_opacus_prefix(state_dict, prefix=\"_module.\"):\n",
    "    \"\"\"Remove the '_module.' prefix added by Opacus from each key.\"\"\"\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        # If the key starts with \"_module.\", strip it off\n",
    "        if k.startswith(prefix):\n",
    "            k = k[len(prefix):]\n",
    "        new_state_dict[k] = v\n",
    "    return new_state_dict\n",
    "\n",
    "# 2.1 Federated Learning Setup \n",
    "\n",
    "def split_dataset_for_federation(train_dataset, num_clients=3, seed=42):\n",
    "    \"\"\"\n",
    "    Splits the given training dataset into `num_clients` subsets.\n",
    "    Returns a list of Subset objects.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    data_size = len(train_dataset)\n",
    "    indices   = np.arange(data_size)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Equal (or almost equal) split\n",
    "    split_sizes = [data_size // num_clients] * num_clients\n",
    "    remainder = data_size % num_clients\n",
    "    for i in range(remainder):\n",
    "        split_sizes[i] += 1\n",
    "    \n",
    "    subsets = []\n",
    "    start_idx = 0\n",
    "    for size in split_sizes:\n",
    "        end_idx = start_idx + size\n",
    "        subset_indices = indices[start_idx:end_idx]\n",
    "        subsets.append(Subset(train_dataset, subset_indices))\n",
    "        start_idx = end_idx\n",
    "    return subsets\n",
    "\n",
    "\n",
    "def train_one_client_federated(model, train_data, device, dp_params, local_epochs=1):\n",
    "    local_model = copy.deepcopy(model)\n",
    "    local_model.train()\n",
    "\n",
    "    # Create local dataloader\n",
    "    local_batch_size = 128\n",
    "    local_loader = DataLoader(train_data, batch_size=local_batch_size, shuffle=True)\n",
    "    \n",
    "    # Define local optimizer & loss\n",
    "    optimizer = optim.SGD(local_model.parameters(), lr=dp_params['lr'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "    # Attach local PrivacyEngine for user-level DP\n",
    "    privacy_engine_local = PrivacyEngine()\n",
    "    local_model, optimizer, local_loader = privacy_engine_local.make_private(\n",
    "        module=local_model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=local_loader,\n",
    "        noise_multiplier=dp_params['noise_multiplier'],\n",
    "        max_grad_norm=dp_params['max_grad_norm'],\n",
    "    )\n",
    "    \n",
    "    # Local training\n",
    "    for _ in range(local_epochs):\n",
    "        for data_batch, target_batch in local_loader:\n",
    "            data_batch, target_batch = data_batch.to(device), target_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(data_batch)\n",
    "            loss = criterion(outputs, target_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Remove the \"_module.\" prefix so that we can load it into the non-wrapped model\n",
    "    cleaned_state_dict = remove_opacus_prefix(local_model.state_dict())\n",
    "\n",
    "    # Return the state_dict and number of samples\n",
    "    return cleaned_state_dict, len(train_data)\n",
    "\n",
    "\n",
    "def federated_avg(state_dicts, data_counts):\n",
    "    \"\"\"\n",
    "    Performs Federated Averaging (FedAvg).\n",
    "    state_dicts: list of parameter dictionaries from each client\n",
    "    data_counts: number of samples for each client, to do weighted averaging\n",
    "    \"\"\"\n",
    "    # Keys in the first state_dict\n",
    "    global_model_dict = copy.deepcopy(state_dicts[0])\n",
    "    \n",
    "    total_data_points = sum(data_counts)\n",
    "    \n",
    "    for key in global_model_dict.keys():\n",
    "        # Weighted sum of the parameter across all clients\n",
    "        global_model_dict[key] = sum(\n",
    "            (state_dicts[i][key] * data_counts[i] for i in range(len(state_dicts)))\n",
    "        ) / total_data_points\n",
    "    \n",
    "    return global_model_dict\n",
    "\n",
    "\n",
    "def federated_training(\n",
    "    global_model, \n",
    "    train_dataset,\n",
    "    test_loader, \n",
    "    device, \n",
    "    dp_params,\n",
    "    num_clients=3,\n",
    "    global_rounds=3,\n",
    "    local_epochs=1\n",
    "):\n",
    "    \"\"\"\n",
    "    High-level loop for Federated Training.\n",
    "    - Splits train_dataset among `num_clients`\n",
    "    - For each global round:\n",
    "        - Each client trains locally (with DP)\n",
    "        - We average (FedAvg) all client model weights\n",
    "    - Returns final global model\n",
    "    \"\"\"\n",
    "    # Split dataset\n",
    "    client_subsets = split_dataset_for_federation(train_dataset, num_clients=num_clients)\n",
    "    \n",
    "    # Initialize global model\n",
    "    fed_model = copy.deepcopy(global_model)\n",
    "    fed_model.to(device)\n",
    "    \n",
    "    for round_idx in range(global_rounds):\n",
    "        client_state_dicts = []\n",
    "        client_data_counts = []\n",
    "        \n",
    "        # Broadcast global model to each client; train locally with DP\n",
    "        for client_idx, subset in enumerate(client_subsets):\n",
    "            state_dict, data_count = train_one_client_federated(\n",
    "                fed_model, subset, device, dp_params, local_epochs\n",
    "            )\n",
    "            client_state_dicts.append(state_dict)\n",
    "            client_data_counts.append(data_count)\n",
    "        \n",
    "        # Average the client models into the new global model\n",
    "        new_global_dict = federated_avg(client_state_dicts, client_data_counts)\n",
    "        fed_model.load_state_dict(new_global_dict)\n",
    "        \n",
    "        # Evaluate on test set after each global round\n",
    "        test_acc, y_prob_test, y_test_true = evaluate(fed_model, test_loader)\n",
    "        print(f\"[Round {round_idx+1}/{global_rounds}] Federated Model Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return fed_model\n",
    "\n",
    "\n",
    "# Federated Training + Comparison\n",
    "\n",
    "# We will reuse the 'train_dataset' from your code above, but we actually only\n",
    "# have: train_dataset, val_dataset, and test_dataset.\n",
    "#\n",
    "# Here, for demonstration, let's do federated learning on the \"train_dataset\".\n",
    "# If you wish, you could also combine train_dataset + val_dataset for more data.\n",
    "\n",
    "# For convenience, let's combine train_dataset + val_dataset into one big set\n",
    "# for the federated simulation. Then we'll test on the same test set.\n",
    "combined_indices = list(range(len(train_dataset))) + [\n",
    "    len(train_dataset) + i for i in range(len(val_dataset))\n",
    "]\n",
    "combined_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
    "\n",
    "# We will define new DP parameters for the federated approach\n",
    "federated_dp_params = {\n",
    "    'noise_multiplier': 1.0,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'lr': 0.01,\n",
    "    'delta': 1e-5\n",
    "}\n",
    "\n",
    "# Create a fresh model (same architecture) for federated training\n",
    "federated_model = SimpleMLP(input_dim, hidden_dim=64, num_classes=num_classes)\n",
    "\n",
    "# Number of clients (federated nodes)\n",
    "num_clients = 3\n",
    "# Number of global rounds\n",
    "global_rounds = 3\n",
    "# Local epochs each client trains per round\n",
    "local_epochs = 1\n",
    "\n",
    "# Perform federated training\n",
    "federated_model = federated_training(\n",
    "    global_model=federated_model,\n",
    "    train_dataset=combined_dataset,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    dp_params=federated_dp_params,\n",
    "    num_clients=num_clients,\n",
    "    global_rounds=global_rounds,\n",
    "    local_epochs=local_epochs,\n",
    ")\n",
    "\n",
    "# Final evaluation of the federated model\n",
    "fed_acc, fed_prob_test, fed_test_true = evaluate(federated_model, test_loader)\n",
    "fed_pred_test = (fed_prob_test >= 0.5).astype(int)\n",
    "\n",
    "fed_prec = precision_score(fed_test_true, fed_pred_test, average='weighted')\n",
    "fed_rec  = recall_score(fed_test_true, fed_pred_test, average='weighted')\n",
    "fed_f1   = f1_score(fed_test_true, fed_pred_test, average='weighted')\n",
    "fed_cm   = confusion_matrix(fed_test_true, fed_pred_test)\n",
    "\n",
    "print(\"\\n=== Federated Model (with DP) Final Evaluation ===\")\n",
    "print(f\"Accuracy:      {fed_acc:.4f}\")\n",
    "print(f\"Precision:     {fed_prec:.4f}\")\n",
    "print(f\"Detection Rate (Recall): {fed_rec:.4f}\")\n",
    "print(f\"F1-Score:      {fed_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", fed_cm)\n",
    "\n",
    "\n",
    "# Compare Federated vs Centralized\n",
    "#\n",
    "# The centralized model metrics were already printed in your original code:\n",
    "#   - test_acc, prec, rec, f1, cm\n",
    "#   - You can reference them to compare with `fed_acc, fed_prec, fed_rec, fed_f1, fed_cm`.\n",
    "#\n",
    "# Example comparison print (uncomment if you want them side by side):\n",
    "print(\"\\n=== Comparison: Centralized vs Federated ===\")\n",
    "print(\"Centralized Model:\")\n",
    "print(f\"  Accuracy:      {test_acc:.4f}\")\n",
    "print(f\"  Recall:        {rec:.4f}\")\n",
    "print(f\"  Precision:     {prec:.4f}\")\n",
    "print(f\"  F1-Score:      {f1:.4f}\")\n",
    "\n",
    "print(\"Federated Model:\")\n",
    "print(f\"  Accuracy:      {fed_acc:.4f}\")\n",
    "print(f\"  Recall:        {fed_rec:.4f}\")\n",
    "print(f\"  Precision:     {fed_prec:.4f}\")\n",
    "print(f\"  F1-Score:      {fed_f1:.4f}\")\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial Threats:\n",
    "\n",
    "Model/Data Poisoning\n",
    "\n",
    "Malicious clients submit crafted updates or train on manipulated data to degrade or backdoor the global model.\n",
    "\n",
    "Inference Attacks\n",
    "\n",
    "Attackers try to recover private information (e.g., membership inference) from aggregated updates.\n",
    "\n",
    "Free-Rider Attacks\n",
    "\n",
    "Malicious participants exploit the system’s resources without contributing meaningful data or updates.\n",
    "\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "\n",
    "Defenses:\n",
    "\n",
    "Differential Privacy\n",
    "\n",
    "Limits per-client leakage by adding noise to gradients.\n",
    "\n",
    "Robust Aggregation\n",
    "\n",
    "Methods like Krum, Bulyan, or Trimmed Mean filter out or downweight outlier (potentially poisoned) updates.\n",
    "\n",
    "Secure Aggregation\n",
    "\n",
    "Cryptographic techniques ensure server only sees aggregated data, protecting individual updates from exposure.\n",
    "\n",
    "Anomaly Detection\n",
    "\n",
    "Screens client updates for suspicious deviations, large gradients, or performance drops on a small validation set.\n",
    "\n",
    "Trusted Execution Environments (TEEs)\n",
    "\n",
    "Protect aggregation and model parameters from tampering at server-level.\n",
    "\n",
    "By combining these measures—especially DP + robust aggregation—you can better secure federated learning against poisoning, privacy leaks, and free-riders while preserving model utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Feature Importance\n",
    "\n",
    "To identify the top five features contributing to intrusion detection, we can use techniques such as feature-importance scores (e.g., from Random Forest, XGBoost) or SHAP values. Below are five features that commonly play a critical role in detecting cyberattacks:\n",
    "\n",
    "Source and Destination IP Flow Counts\n",
    "\n",
    "Helps detect unusual communication patterns, which are common in DDoS attacks.\n",
    "Packet Size Distribution\n",
    "\n",
    "Abnormal packet sizes may indicate an attempt to exfiltrate data or flood a network.\n",
    "Connection Duration\n",
    "\n",
    "Extremely short or long connections may indicate scanning behavior or persistent infiltration techniques.\n",
    "Request/Response Ratios\n",
    "\n",
    "Sudden spikes in request rates could be a sign of brute-force or credential-stuffing attacks.\n",
    "Entropy of Payload Data\n",
    "\n",
    "High entropy can suggest encrypted malicious payloads or obfuscated attack traffic.\n",
    "These features help detect various cyberattacks, such as:\n",
    "\n",
    "DDoS Attacks: Characterized by abnormally high packet counts and connection requests.\n",
    "Phishing: Revealed by unusual request-response patterns to malicious domains.\n",
    "Data Exfiltration: Indicated by large payload sizes over extended connections.\n",
    "Attackers may also try to recover private information (e.g., membership inference) from aggregated model updates or exploit free-rider attacks, where they leverage the system’s resources without contributing meaningful data.\n",
    "\n",
    "3.2 Custom Feature Design\n",
    "\n",
    "To further improve intrusion detection, we propose two additional cybersecurity-relevant features:\n",
    "\n",
    "Behavioral Anomaly Scores\n",
    "\n",
    "Extraction: Use statistical baselines for normal network behavior (e.g., clustering techniques) and compute deviations for each connection.\n",
    "Impact: Improves classification accuracy by detecting novel (zero-day) and adaptive threats.\n",
    "Temporal Traffic Patterns\n",
    "\n",
    "Extraction: Perform time-series analysis on log timestamps to detect periodic or time-based attack strategies (e.g., slow brute-force attempts).\n",
    "Impact: Enhances detection of stealthy attacks that operate under the radar over extended periods.\n",
    "Defenses\n",
    "\n",
    "Differential Privacy: Limits per-client data leakage by adding noise to gradients in federated or distributed learning.\n",
    "Robust Aggregation: Methods like Krum, Bulyan, or Trimmed Mean filter out or downweight outlier (potentially poisoned) updates.\n",
    "Secure Aggregation: Uses cryptographic techniques so that the server only sees aggregated data, protecting individual updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Real-World Deployment Challenges\n",
    "\n",
    "Deploying a privacy-preserving ML system in large enterprises comes with several challenges:\n",
    "\n",
    "Scalability\n",
    "\n",
    "Issue: Differential privacy (DP) often increases computational overhead, making large-scale deployment resource-intensive.\n",
    "Solution: Adopt model-compression techniques and distributed computing frameworks to manage computational loads.\n",
    "Latency Constraints\n",
    "\n",
    "Issue: DP-SGD and federated learning introduce delays due to added noise and decentralized updates.\n",
    "Solution: Implement hybrid models that combine local DP training with periodic centralized refinements, balancing performance and efficiency.\n",
    "Adaptability to Emerging Threats\n",
    "\n",
    "Issue: Cyber threats evolve quickly, and privacy-preserving models may be slow to adapt.\n",
    "Solution: Use continual learning techniques with DP, allowing models to learn from new threats while preserving privacy.\n",
    "By combining advanced feature engineering, robust aggregation methods, and privacy-preserving techniques, organizations can improve their intrusion detection capabilities while maintaining the confidentiality of sensitive data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
